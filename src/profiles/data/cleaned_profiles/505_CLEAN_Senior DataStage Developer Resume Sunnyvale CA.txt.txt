SUMMARY: 10 years of experience in analysis, design, development, testing, maintenance and implementation of ETL methodologies in all phases of Data warehousing life cycle and Relational databases using IBM InfoSphere DataStage 11.3/9.1/8.5/8.1. Thorough understanding of DW principals (Fact Tables, Dimensional Tables, Dimensional Data Modeling - Star Schema and Snow Flake Schema). Deep understanding of OLTP, OLAP and data warehousing environment and tuning both kind of systems for peak performance. Familiar in using highly scalable parallel processing Infrastructure using DataStage Enterprise Edition (Parallel and Server). Expert in Data Warehousing techniques for Data Cleansing, Slowly Changing Dimension phenomenon (SCD), Surrogate Key assignment and CDC (Change Data Capture). Expert in designing Parallel jobs using various stages like Join, Merge, Sort, Copy, Lookup, RemoveDuplicates, Filter, Funnel, Dataset, Complex flat file, Modify, Aggregator, XML, Transformer, Change Apply, Row Generator, Column Generator and many other stages. Experience in working wif parallel extender for splitting bulk data into subsets to distribute teh data to all available processors to achieve best job performance. Experienced in Performance Tuning, Bug Fixing and Trouble Shooting of Data Stage Jobs. Experienced in Oracle PL/SQL to develop oracle functions, stored procedures, packages, triggers and experienced in in corporation of various data sources like Oracle, SQL server, DB2, Flat files, Teradata, Mainframe sources, datasets operational sources into teh staging area. Experienced in Data Warehousing, Application Development and Production Support, also good Experience wif different RDBMS like Oracle 11g/10g/9i/8i, DB2 for ZOS and DB2 for Unix. Expertise in creating reusable components such as Shared containers, Local Containers and in creating custom transformations, functions, routines. Experienced in performance tuning, bug fixing and troubleshooting of DataStage jobs. Worked on Scheduling tools like Autosys, Control-M for automating jobs run. Worked on Unix shell scripts for teh scheduling of sessions, automation of processes, also for pre/post session scripts. Experience in coordinating wif offshore and offsite teams to resolve design, development and testing issues. Having excellent track record as a strong team player wif effective communication, analytical, multi-tasking skills, resourceful, result driven, ability to grasp quickly and self-motivated. TECHNICAL SKILLS: ETL Tools: IBM Info sphere DataStage 11.5/9.1/8.7/8.5/8.0.1/7.5 Operating Systems: UNIX, Windows NT/ 2000/XP, Windows7, Unix, AIX/Linux Database: Teradata-15.10.1.4, Oracle11g/10g/9i/8i, MS Access, DB2 for ZOS V9/V10, DB2 V10 for Unix, MS-SQL Server, HP Vertica databases. Languages: SQL, PL/SQL, C++, UNIX Shell scripting, JIL (Job Information Language), COBOL, JCL, REXX DW/ETL Concepts: IBM InfoSphere DataStage Suite, IBM DataStage 8.0.1/7.5.2/7.1/7.0 Parallel Extender (PE), SSIS 2008/2012, Information Analyzer, Metastage 6.0, Cognos 6.0/5.x, Data Mining, Tableau Desktop/Server, OLAP and OLTP. Data Modelling: Data Modeling, Star Schema Modeling, Snow-Flake Modeling, FACT and Dimensions, Physical and Logical Data Modeling, Erwin 3.5.2/3.X PROFESSIONAL EXPERIENCE: Confidential, Sunnyvale CA Senior DataStage Developer Responsibilities: Worked on IBM InfoSphere DataStage 11.3 to develop processes for extracting, cleansing, transforming, integrating, and loading data into data warehouse database. Designing ETL jobs incorporating complex transform methodologies using Data Stage tool resulting in development of efficient interfaces between source and target systems. Developed/Modified Parallel jobs using Parallel stages like: Dataset, Sequential file, Funnel, Filter, Modify, Merge, Join, Lookup, Transformer and External Source Stage. Implemented data extraction, transformation and load processes in a parallel framework. Used stages like Transformer, sequential, Aggregator, Data Set, File Set, CFF, Remove Duplicates, Sort, Join, Merge, Lookup, Funnel, Copy, Modify, Filter, Change Data Capture, Change Apply, Head, Tail, Sample, Surrogate Key, External Source, External Target, Compare, Teradata Connector. Developed/ Modified teh JIL (Job Information Language) Jobs in Autosys for scheduling teh batch process. Worked wif widely used stages like Flat File, Lookup, Join, Pivot, Transformer, Sort, Aggregator, Merge, Row Generator, and Column Generator, FTP and troubleshoot teh designed jobs and tested teh jobs for all logical errors. Customizing teh Datastage Parallel jobs as per current business enhancements. Worked on DataStage V9.1 to developETLjobs dat loads teh data from staging to target tables in Teradata server as database. Involved in Performance and Tuning teh Parallel Extender jobs to teh maximum extent and achieved teh best performance by reducing teh Loading Time. Used different Parallel Extender Partitioning techniques in teh stages to facilitate teh best parallelism in teh Parallel Extender jobs. Used shared containers for multiple jobs, which have teh same business logic. Involved in performance tuning of teh Data Stage jobs and queries. Extensively used Hash File Concept to improve performance. Involved in unit testing and validating teh jobs before & after deployment of teh codes. Environment: IBM InfoSphere DataStage 9.1 (Designer, Administrator, Director), CA-Software Change Manager /Harvest, Teradata Server, Teradata SQL Assistant, Windows 7, IBM Rational Quest, Autosys, Unix Shell Scripting, AUTOSYS JIL (Job Information Language), Winscp Confidential, Malvern PA Senior DataStage Developer Responsibilities: In AGILE, halped teh team in planning teh sprint by identifying modules and creating stories. Created COBOL-DB2, COBOL-IMS, CICS modules, insert/update or delete from DB, JCLs to execute teh modules. Coded native stored procedures using IBM Datastudio to support our application UI to interact wif DB2 database. Extensively used BMC and IBM Datastudio to do EXPLAINS on stored proc queries to understand teh access path and optimized teh queries accordingly. Designed and developed aREXX utility to parse COBOL/CICS source code and identify/create copybooks contained wifin and integrated wif teh CLIST to make it an invokable command. REXXscripts were written and run in teh production environment as well as teh test environment to verify teh FTP data transfers and data integrity of testing data. Used File-Aid for DB2, QMF and SPUFI for accessing teh DB2 database. Created DCLGENs and used them in COBOL modules. Used DB entities Views, Indexes and DB concepts like Triggers to handle & maintain data. Used Endevor tool to maintain teh COBOL modules, JCLs, parms and procs and for promoting teh same to higher environments. Used MainframeExpress to debug teh COBOL modules and perform teh unit testing. Used NDM and FTP TEMPhas file transfer protocols between mainframe LPARs and between mainframe and midrange servers respectively. Used CA-7 as teh scheduler tool for all teh batch flows inside teh application. Created Ezetrieve codes, Sort utilities like SyncSort and IBM DB utilities using JCL and framed teh job flows for batch processing of application data. Environment: IBM InfoSphere DataStage 9.1 (Designer, Administrator, Director), CA-Software Change Manager /Harvest, Teradata Server, Teradata SQL Assistant, Windows 7, IBM Rational Quest, PAC 2000(BMC remedy tool), Autosys, Unix Shell Scripting, AUTOSYS JIL (Job Information Language), WinSCP, Anthill Pro 5.0 Confidential, Newark DE Senior Datastage Developer Responsibilities: Worked on IBM InfoSphere DataStage 9.1 to develop processes for extracting, cleansing, transforming, integrating, and loading data into data warehouse database. Implementing Industry ETL standards and best practices, performance tuning during designing teh Datastage Jobs. Developed Parallel jobs using Parallel stages like: Dataset, Sequential file, Funnel, Filter, Modify, Merge, Join, Lookup, Transformer and External Source Stage. Used stages like Transformer, sequential, Aggregator, Data Set, File Set, CFF, Remove Duplicates, Sort, Join, Merge, Lookup, Funnel, Copy, Modify, Filter, Change Data Capture, Change Apply, Head, Tail, Sample, Surrogate Key, External Source, External Target, Compare. Involved in Performance and Tuning teh Parallel Extender jobs to teh maximum extent and achieved teh best performance by reducing teh Loading Time. Used different Parallel Extender Partitioning techniques in teh stages to facilitate teh best parallelism in teh Parallel Extender jobs. Designed XML stages for reading XML log files for capturing data stage jobs audit data. Created master controlling sequencer jobs and scheduled it using AUTOSYS. Involved in performance tuning of teh Data Stage jobs and queries. Environment: IBM InfoSphere DataStage 9.1 (Designer, Administrator, Director), Business Objects 7.0, SQL Server 2000, SQL Query Analyzer, Windows NT/ XP. Confidential, Jersey City, NC IBM DataStage Developer Responsibilities: Expertise in designing and implementing Datastage Architecture in data warehousing and Business Intelligence projects. Worked wif Functional team and Data Modelers/Architects to identify and understand teh data from different source systems. Developed ETL packages wif different data sources (SQL Server, Flat Files, Excel source files, XML files etc) and loaded teh data into target tables by performing various kinds of transformations using SQL Server Integration Services (SSIS) Migrated teh Existing DTS packages to teh SSIS Batch jobs and enhanced teh packages wif monitoring features so dat audit information of teh packages and their execution results are loaded in to teh audit table. Worked on teh Data base design & data model - Logical & Physical design wif hands on experience on DDL and DML SQL operations. Created Datastage jobs (ETL Process) for populating teh data into teh Data warehouse constantly from different source systems like ODS, flat files, scheduled teh same using IBM DataStage Sequencer for SI testing. Preparing development timing plans & reporting to senior management about teh supplier progress system & ensuring their engineering support for onsite integration & production launch. Used SQL Profiler for troubleshooting, monitoring, and optimization of SQL Server and non-production database code as well as T-SQL code from developers and QA. Designed and implemented Parameterized and cascading parameterized reports using SSRS. Automated process of job monitoring which halped in minimizing teh manual intervention & documenting them perfectly. Developed teh reusable components, best practices dat were later used in other Data warehouse. Environment: Data Stage 8.X, DB2 UDB, Oracle 11g, UNIX, MICROSOFT VISIO, control-M, SQL plus, WinCVS, AUTOSYS, MS SQL Server 2008 (SSIS/SSRS). Confidential, Charlotte, NC Senior ETL Developer Responsibilities: Reviews existing data dictionaries and source to target mappings. Participate in Data modeling discussions, exchange thoughts to come up wif a best model to efficiently serve both ETL teams and reporting teams. Designed complex DataStage mappings and re-usable transformations to facilitate Initial, Incremental and CDC data loads and parameterize to source from multiple systems. Worked on SSIS/DTS Package Import/Export for transferring data from Database (Oracle and Text format data) to SQL Server. Used various control flow tasks such as bulk insert task, transfer job task, different data flow tasks and FTP task along wif For Loop and For Each Loop containers to create SSlS packages. Worked on SSIS performance tuning using counters, error handling, event handling, re-running of failed SSIS packages using checkpoints. Created stored procedures to transform teh data and worked extensively In T-SQL for various needs of teh transformations while loading teh data. Extensive Experience in writing SQL, PL/SQL queries, stored procedures, functions, packages and database triggers, exception handlers. Environment: IBM Info sphere Datastage v7.5/8.5, Informatica Power center8.6, UNIX, Shell scripting, control M, Erwin, Teradata, Oracle, PL/SQL Confidential, Charlotte IBM Datastage Developer Responsibilities: Implemented Data Quality process which transforms teh input fields into teh data types used in teh target database tables and does basic checks on teh data fields and reports teh data errors. Developed Parallel Jobs which loads Dimension Tables and maintained Surrogate key generation in multiple run. Extensively dealt wif change capture techniques for implementing slowly changing dimensions process. Familiar wif import/export of DataStage Components (Jobs, DS Routines, DS Transforms, and Table Definitions) between DataStage Projects, use of Dataset Management (DSM) utility and multiple jobs compile utility wif use of Data Stage Director. Developing shell scripts to automate file manipulation and data loading procedures. Used Shared container for simplifying design and maintenance. Experienced in fine tuning, Trouble shooting, bug fixing, defect analysis in DataStage Jobs. Used error handler process Jobs to capture look up failure, duplicates and data type errors and these errors are captured to an error log detail table. Created process flow diagrams using Microsoft VISIO. Documented teh development process and performed knowledge transfer to Business Intelligence team. Environment: Data Stage/Quality Stage 8.0 (IBM WebSphere Data stage and Quality Stage Designer, Director, Administrator), DB2 UDB 9.2, SQL Server 2000, Linux 10, SQL, PL/SQL, UNIX Shell Scripting, Microsoft Visio, DB2 Visualizer, MS SQL server, Mainframe, COBOL. Confidential  Mainframe Developer Responsibilities: Created high-level and low-level design documents from teh requirements documents. Worked as a team to develop a database for teh application, logically grouped teh data in teh form of tables, defined columns in teh tables, defined teh constraints, created and executed DDL statements. Created JCLs to frame teh job flow to develop various modules wif in teh application. Created COBOL-DB2 programs to format teh data, apply business cases and tan insert, Update or delete into database. Used ChangeMan as teh version control tool for COBOL modules and teh JCLs code Prepared teh Unit test scripts and unit tested teh COBOL-DB2 modules and mainframe job flows extensively. Extensively used XPEDITOR as teh debug tool to test teh code modules. Used teh IBM Load and Unload utilities for teh bulk load and extraction of data. Handled very high volumes of data for batch processing. Used File-Aid for DB2, QMF and SPUFI for accessing teh DB2 database. Created DCLGENs and used them in COBOL modules. Used tools like Syncsort. Used VISUAL EXPLAINS tool to analyze and optimize teh performance of an SQL query. Created DB2 Stored Procedures using COBOL for manipulating and fetching data for teh web server calls made from front end application. Created COBOL codes for accessing, reading and editing teh VSAM datasets. Created Ezetrieve codes for file comparison and data manipulation and formatting activities. Used NDM and FTP TEMPhas file transfer protocols between mainframe LPARs and between mainframe and UNIX servers. Environment: COBOL, DB2, JCL, Ezetrieve, SyncSort, MS SQL Stored Procedures, Endevor, Xpeditor, BMC Explains, CA-7, MS Visio, Quality Center, SharePoint 