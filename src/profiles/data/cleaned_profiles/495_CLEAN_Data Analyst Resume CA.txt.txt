SUMMARY Around 4 years of experience in Data Analysis, Data Conversion, Data Validation, Data Profiling, UAT Testing and Report Creation and working experience in Tableau, Teradata, AWS Redshift, AWS S3, Python, Unix and Oracle. Experience in Teradata, SQL and Utilities like Tpump, Multiload and Fast load. Good experience in Developing Teradata SQL queries and using Utilities such As BTEQ Strong experience in using Excel and MS Access to dump teh data and analyze based on business needs. Experience in Creating Teradata SQL scripts using OLAP functions like rank and rank () Over to improve teh query performance while pulling teh data from large tables. Experience in data analysis using Python (Pandas, NumPy) Experience in moving data to cloud platform like AWS (S3) and manipulate data using Redshift. Worked on performance tuning and optimization to improve teh efficiency in script executions. Good working experience loading Data Files in AWS Environment and Performed SQL Testing on AWS redshift databases. Exceptional ability to research, analyze and convey complex technical information to diverse end - users at all levels. Solutions-driven strategist who consistently improves efficiency, productivity and teh bottom line. Recognized for partnering wif business leaders and technical teams to plan, integrate, document and execute complex project plans on time and on budget. Ability to work wif multiple business stakeholders, application, DBA, development teams to establish a collaborative work environment. Developed reporting dashboard of business data, metrics and measures in order to allow consumers to align and track against overall business strategies, goals and objectives ultimately enabling them to make informed decision and driving operational strategies. Performed root cause analysis of teh recurring issues by debugging application ultimately improved application stability, efficiency, and usability. Understood teh functional and technical aspects of application to track issues and to provide quick solutions. Delivered in software development life cycle for various ETL and BI projects. Provided end-to-end solutions for requirement analysis, design, development, testing, and application maintenance. Identified organization process inefficiencies and gaps, implemented process improvement methodologies to streamline teh process and to increase efficiencies. Maintained teh application code quality at teh organization level ensuring robust, stable applications Automated teh processes requiring manual interventions using SSIS, SQL, SSRS. Power BI, and Tableau+ to reduce number of incidents, to maximize customer satisfaction, and to increase application usability. Tuned SQL queries to reduce cycle time, improving process execution time and ultimately stabilizing applications. Demonstrated attention to details, decision-making, problem solving, and critical thinking in teh service delivery. Communicated findings using teh most TEMPeffective form of written and verbal communication to non-technical users. Experience in working under Agile (Scrum) and waterfall models of software development life cycle. Ability to meet deadlines and handle multiple tasks, team player, motivated, able to grasp things quickly wif analytics and problem-solving skills. TECHNICAL SKILLS: Operating Systems:  Windows XP, Windows 7/10 Specialties:  Data Visualization, Business Intelligence (BI), Software Management, Data Collection. Languages:  SQL, PL/SQL, XML, HTML, Java, C,Python BI Tools:  Tableau Desktop/Public/Server, QlikView Data Bases:  Oracle 11g/10g, MS SQL Server 2008, Teradata, Snowflake, Amazon Web Serices (AWS) Document Management:  SharePoint Modeling Tools:  Dimensional Data Modeling, Multi-dimensional modeling, Snowflake/Star Schema Others:  MS Word, Excel, Visual Studio, Astah, Rational rose, Notepad++, JIRA PROFESSIONAL EXPERIENCE Data Analyst Confidential - CA Responsibilities: Involved in analysis, design and documenting business reports such as Executive summaries, Scorecards and drilldown reports. Interacted wif Business analysts to understand data requirements to ensure high quality data is provided to teh customers. Developed scripts using Teradata advanced techniques like Row Number and Rank Functions. Worked on performance tuning and Query Optimization for increasing teh efficiency of teh scripts. Extracted data from existing data source and performed ad-hoc queries by using SQL. Using advanced Excel features like Pivot tables and Charts for generating Graphs. Worked on completing teh metadata documentation for teh projects. Created monthly and quarterly business monitoring reports. Developed BTEQ scripts in UNIX using Putty and used cron-tab to automate teh batch scripts and execute scheduled jobs in UNIX. Developed Python programs for manipulating teh data reading from various Teradata Tables and convert them as one CSV Files, update teh Content in teh database tables. Used Python modules like Pandas and NumPy and date time to perform extensive data analysis. Performed transformations on loaded datasets using Python over teh spark engine using both batch and streaming data Moved data from AWS S3 buckets to AWS Redshift cluster by using CLI commands. Performed verification and validation for accuracy of data in teh monthly/quarterly reports. Good noledge on Json format data and performed teh source, target validations using aggregations and null validity functions. Created multi-set tables and volatile tables using existing tables and collected statistics on table to improve teh performance. Supported teh users of application wif using multiple SQL and PL/SQL techniques. Designed stunning visualizations using tableau software and publishing and presenting dashboards on web and desktop platforms. Implemented point of view security to Tableau dashboards to facilitate visibility across various levels of teh Organization. Creates daily tasks for analysts using Jira Gets OSLA approved for teh assigned schema Design and implement reporting solution architecture Wrote SQL queries for data manipulation to meet data specifications for reports. Develops stored procedures, queries, views and Parameters necessary to support SSRS reports Deployed complex reports in SSRS server and converted reports from Microsoft MS to SSRS. Analyzing and profiling data returned for data integrity and business decisions Responsible for migrating legacy reports to a new platform by rebuilding them to meet current business requirements. DATA ANALYST Confidential, TX Responsibilities: Deployed and implemented information management systems which collected data from over 4,700 participants. Performed data merging, cleaning, and quality control procedures by programming data object rules into a database management system. Actively reviewed over 208 unique variables and 4,700 rows of data using Excel and Python. Created detailed reports for management. Reported daily on returned survey data and thoroughly communicated survey progress statistics, data issues, and their resolution. Assisted in teh development of a new data review and coding system which finished delivery task two weeks early and required TEMPfewer staff to complete overall. Performed data harmonization between two distinct data sources to create a master data delivery file. Coordinated and technical materials for a staff of five in survey collection and issue resolution. Develop a master data flowchart which was used to measure teh completion of study objectives. Served as primary contact for teh acceptance or rejection of surveys where unique or rare issues were involved. Involved in Data analysis and quality check Created teh source to target mapping spreadsheet detailing teh source, target data structure and transformation rule around it. Wrote Python scripts to parse XML documents and load teh data in database, used Python to extract weekly information from XML files, Developed Python scripts to clean teh raw data. Worked on datasets of various file types including HTML, Excel, PDF, Word, XML and its conversions. Involved in testing teh XML files and checked whether data is parsed and loaded to staging tables. Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies Performed Database and ETL development per new requirements as well as actively involved in improving overall system performance by optimizing slow running/resource intensive queries. Implemented big data processing applications to collect, clean and normalization large volumes of open data using Hadoop ecosystems such as PIG, HIVE, and HBase. Python and resolved customer issues and recommended solutions for improvement. Developed data mapping documentation to establish relationships between source and target tables including transformation processes using SQL. Created Data Quality Scripts using SQL and Hive to validate successful data load and quality of teh data. Created several types of data visualizations using Python and Tableau. Data wrangling and scripting in Python, database cleanup in SQL, advanced model building in R/Python, and expertise in data visualization and Tableau dashboard development. TEMPEffectively led multiple client projects. These projects contained a heavy Python, SQL, Tableau, modeling, and forecasting component. Created views in Tableau Desktop that were published to internal team for review and further data analysis and customization using filters and actions. Environment: Tableau, SQL, UNIX, JSON, Jira, HADOOP (HDFS), Hive, Sqoop, Spark, JAVA, HBase,Python, AWS, SSIS, Teradata, Oracle 10g. Data Analyst Confidential  Responsibilities: Involved in analysis, specification, design, and implementation and testing phases of Software Development Life Cycle (SDLC) and used agile methodology for developing application. Working as an application developer experienced wif controllers, views and models in Django Used Salt Stack to configure and manage teh infrastructure Restful web services using Python REST API Framework. Implemented teh application using Python Spring IOC (Inversion of Control), Django Framework and handled teh security using Python Spring Security. Tested entire frontend and backend modules using Python on Django Web Framework Responsible for handling teh integration of database system. Developed Server-side automation using Node JS scripting and connecting different types of SQL and NoSQL stores from Node JS. Used object-relational mapping (ORM) solution, technique of mapping data representation from MVC model to Oracle Relational data model wif an SQL-based scheme. Implemented Performance tuning and improved teh Performance of Stored Procedures and Queries. Installed and configured py Builder for application builds and deploying it. Used Selenium Library to write fully functioning test automation process that allowed teh simulation of submitting different we request from multiple browser to web application. Developed and Deployed SOAP based Web Services on Tomcat Server. Used Jenkins for continuous integration for code quality inspection and worked on building local repository mirror and source code management using Git hub. Used IDE tool to develop teh application and JIRA for bug and issue tracking. Wrote unit testing codes using unit test, resolving bugs and other defects using Firebug. Used JIRA to assign, track, report and audit teh issues. Used GIT to coordinate team development. Environment: Tableau, SQL, UNIX, JSON, Jira, HADOOP (HDFS), Hive, Sqoop, Spark, JAVA, HBase, AWS, SSIS, Teradata, Oracle 10g. SQL Developer Confidential Responsibilities: Gather data from different data sources like MySQL, Oracle and SQL Server Develop reports, dashboards using Tableau 9.3 for quick reviews to be presented to Business and IT users. Developed POCs by building reports and dashboards using Tableau to perform Statistical analysis of large data Developed Ad-hoc reports using Tableau Desktop, Excel Prototyped data visualizations using Charts, drill-down, parameterized controls using Tableau to highlight teh value of analytics in Executive decision support control. Developed visualizations using sets, Parameters, Calculated Fields, Dynamic sorting, Filtering, Parameter driven analysis. Used SQL Server Reporting Services (SSRS) and SQL Server Management Studio 2008 -SSIS, SSAS, and SQL Profiler, including Crystal Reports to run scripts and maintain stored procedure and code functions across company's Databases Performed schema changes in teh database per request and met wif clientele and wif various subgroups for requirement gathering in order to allow self-extracted reports and created critical field reporting tools for Enterprise Data Management customer segments Validated data to correctly reflect reservations for passengers and carrying capacity of cargo. Created SQL stored procedures using SQL Query Analyzer and Transact-SQL as data sources for reports. Trained, mentored, supervised, and advised over a dozen analysts in teh development of programs. Acted as a point of contact for answers to questions over two groups. Trained analysts in development standards; according to corporate models and paradigms. Developed databases to interface wif SQL Server, Oracle, and MS Access databases. Developed and supported applications for teh Revenue Management and Revenue Management Environment: Tableau, SQL, UNIX, JSON, Jira, HADOOP (HDFS), Hive, Sqoop, Spark, JAVA, HBase, AWS, SSIS, Teradata, Oracle 10g. 