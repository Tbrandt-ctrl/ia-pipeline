SUMMARY Over 9+ years of total IT experience andTechnical proficiency in the Data Warehousing involving Business Requirements Analysis, Application Design, Data Modelling, Development, Database Administration, testing and documentation. Experience in Teradata Database design, implementation, and administration mainly in large - scale Data Warehouse environments. Proficient in Teradata Database Design (Physical and Logical), Application Support, Performance Tuning, Optimization, User & Security Administration, Data Administration and setting up the Test Development environments and Teradata Active System Management (TASM). Experience in Teradata V14,V13, V12, V2R6, SQL, Data Warehouse Modelling, Teradata Utilities, Aggregates and building efficient views. Good experience in Teradata RDBMS using FastLoad, MultiLoad, TPump, FastExport, Teradata SQL Assistant and BTEQ Experience in OLTP/OLAP System Study, Analysis and E-R modelling, developing Database Schemas like Star schema and Snowflake schema (Fact Tables, Dimension Tables) used in relational, dimensional and multidimensional modelling Proficient in converting logical data models to physical database designs in Data warehousing Environment and in-depth understanding in Database Hierarchy, Data Integrity concepts and Data Analysis Experience in Coding Teradata SQL, Teradata Stored Procedures, Macros and Triggers Worked on full lifecycle of various projects, including requirement gathering, system designing, application development, enhancement, deployment, maintenance and support Experience in Query Analyzing, performance tuning and testing Experience in writing UNIX Korn shell scripts to support and automate the ETL process Technical expertise in ETL methodologies, Informatica 6.x/7.x/8.x - Power Center, Power Mart, Client tools-Mapping Designer, Workflow Manager/Monitor and Server tools - Informatica Server Manager, Repository Server Manager, and Power Exchange Experience in testing the applications and creating test cases for Unit Testing, Integration Testing and make sure the data extracted from source is loaded into target properly in the right format Experience in troubleshooting of Informatica jobs and addressing issues like performance tuning and enhancements TECHNICAL SKILLS Primary Tools:  Teradata SQL, Teradata tools & Utilities Teradata Utilities:  BTEQ, FastLoad, MutliLoad, Fast Export, Tpump, SQL Assistant, Teradata Manager, Archive/Restore, configuration/Reconfiguration, Table Rebuild, Teradata Parallel Transport utility(TPT) Languages:  Teradata SQL, SQL,PL SQL, C Databases:  TeradataV2R6.x/  12.0/13.0/14.0 (Developing), Oracle 10g Reporting/ETL Tools:  Informatica, Business Objects, Crystal Reports, OBIEE,COGNOS Operating Systems:  Windows 95/98/NT/2000/XP, Unix Data Modeling:  Erwin4.0/3.5,Logical/Physical/Dimensional/3NF, Star/ ETL, OLAP, ROLAP Scripting Languages:  UNIX Shell Scripting, BTEQ. PROFESSIONAL EXPERIENCE Confidential, Fremont, CA Teradata Developer Responsibilities: Involved in Requirement gathering, business Analysis, Design and Development, testing and implementation of business rules Worked with the data modelers, architects and OBIEE developers. Performance optimization on the data and consumption layer in Teradata Create and Maintain Teradata Tables, Views, Macros, Triggers and Stored Procedures Coding using Teradata Analytical functions, write UNIX scripts to validate, format and execute the SQLs on UNIX environment. Create, and regular tuning of physical database objects (tables, views, indexes) to support normalized and dimensional models Worked on CIM, RTIM at the times of working on sales force when used to maintaining and working with data in cloud. Provide ongoing support by developing processes and executing object migrations, security and access privilege setup and active performance monitoring Captured Queries from OBIEE and did performance tuning on those queries Created a BTEQ script for pre population of the work tables prior to the main load process Used volatile table and derived queries for breaking up complex queries into simpler queries. Create and Maintain Teradata Databases, Users, Tables, Views and Macros Coding using Teradata Analytical functions, BTEQ SQL of TERADATA, write UNIX scripts to validate, format and execute the SQLs on UNIX environment Developed processes on both Teradata using shell scripting and RDBMS utilities such as Multi Load, Fast Load, Fast Export, BTEQ (Teradata), Exposure to Tpump on UNIX environments Converted the data mart from Logical design to Physical design, defined data types, Constraints, Indexes, generated Schema in the Database, created Automated scripts, defined storage parameters for the objects in the Database Responsible for loading data into warehouse from different sources using Multiload and Fastload to load millions of records Involved in Performance tuning for the long running queries Developed UNIX shell scripts to run batch jobs in production Performed tuning and optimization of complex SQL queries using Teradata Explain Application development that enables data to be moved from legacy systems and external data sources into a staging area for the transformation effort to final data load into the Enterprise data warehouse Teradata, the tools extensively used were Multiload, Fastload, Fastexport, and BTEQ Apply broad in- depth business and technical knowledge to resolve production support and sustainment activities Led the development Team of 5 members, estimated the work efforts in terms of hours and resources based on the requirements Collaborated with Project Manager to prioritize development activities and subsequently handle task allocation with available team bandwidth Environment: Teradata 13.0, Teradata Administrator, Teradata SQL Assistant, Teradata Manager, BTEQ, MLOAD, FLOAD, FASTEXPORT, UNIX, Unix Shell scripts, Informatica,OBIEE Confidential, Jersey City, NJ Teradata Developer Responsibilities: Involved in DBA activities in the tests, such as creation of users, spool, temporary, permanent space. Involved in database design/preparing SQL scripts to support the larger databases that involves terabytes of data. Creation of BTEQ, Fast export, MultiLoad, TPump, Fast load scripts. Worked on complex queries to map the data as per the requirements. Designed and implemented stored procedures and triggers for automating tasks in SQL. Design, create, and regular tuning of physical database objects (tables, views, indexes) to support normalized and dimensional models Analyze the current data movement (ETL (Informatica)) process and procedures. Loading data by using the Teradataloader connection, writing Teradata utilities scripts (Fast Load, Multiload) and working with loader logs. Interact with business partners for the design based on their Business requirements. Worked extensively with Teradata utilities BTEQ, Multiload, Fastload, TPUMP, and Fast export for data analysis purpose Monitoring the performance of Teradata system with newTeradatafile system having WAL feature embedded. To monitor query run times using Teradata Performance Monitor Involved in writing TD Stored procedures, Macros, SQL scripts for transformation. Review code and design developed by the offshore team and leading offshore team for the DDLâ€™s and other coding. Experienced in using Priority Scheduler. Involved in loading of data intoTeradatafrom legacy systems and flat files using complex MLOAD scripts and FASTLOAD scripts. Created Teradata External loader connections such as MLoad, Upsert and Update, Fast Load while loading data into the target tables in Teradata Database. Used VERITAS Netbackup tool in order to design Archival/Recovery Jobs. We manage whole Archival/Recovery Process using Perl scripting and VERITAS Netbackup tool Created ad hoc reports using BTEQ. Environment: Teradata Visual Explain, BTEQ, Teradata Manager, Teradata SQL Assistant, Fast Load, MultiLoad, Fast Export, Rational Clear Quest, Control-M, UNIX, MQ, NDM, FTP, SAS, Ab Initio (GDE 1.14, Co>OS: V1.14) EME. Confidential, SFO, CA Teradata Developer Responsibilities: Actively participated in transforming enhanced logical data model to physical data model Actively involved in Data Gathering, recognizing and confirming the data sources/elements Worked on installation, configuration of Oracle, Informatica and extensively worked on Repository manager Extensively used ETL to load data from flat files into Staging area and then to Data warehouse Experience in performance tuning of sources, mappings, targets and sessions Implemented various Teradata specific features like selection of PI, USI/NUSI, PPI and Compression based on requirements Implemented access rights mechanism using restricted views, macros and roles Responsible for space management and user management including accounting based on performance group allocation Provide ongoing Teradata system performance management using Teradata manager and PMON Reviewing and monitoring priority scheduler and TDQM settings Involved heavily in writing complex SQL queries based on the given requirements and used volatile tables, temporary tables, derived tables for breaking up complex queries into simpler queries Gather information from different data warehouse systems and loaded into warehouse usingFastLoad, FastExport, MultiLoad, BTEQ and Unix shell scripts Involved in unit testing, systems testing, integrated testing and user acceptance testing. Involved in 24x7 production support model. Environment: Informatica Power Center 7.x and 8.x, NCR Teradata V2R5, Oracle8i, SQL, C, C++, Shell scripting, Teradata Manager, Teradata Administrator, TDQM, Priority scheduler, BTEQ, SQL Assistant, TSET, Index Wizard, Statistics wizard, FastLoad, MultiLoad, FastExport, Tpump. Confidential, Chicago, IL Teradata Developer Responsibilities: Created Fast Load, Fast Export, Multi Load, Tpump, BTEQ scripts. Monitor and maintain a production Teradata database environment, including runtime optimization, capacity management and planning, security, configuration, scheduling, and execution of maintenance utilities. Technical expert in the areas of relational database logical design, physical design, and performance tuning of the RDBMS. Maintain and Tune Teradata Production and Development systems. Supported application development time lines by implementing designs as well as incremental changes to database definition in a timely manner into production and non-production Teradata systems. Perform tuning and optimization of database configuration and application SQL Define database backup & recovery strategies, implement and administer. Create and Maintain users for Production/Development Teradata Systems. Dynamically set query priorities using Teradata scheduler. Capacity Planning: Re-size storage and spool space proactively, to accommodate growing data content. Involved in converting existing Oracle data into Teradata. Involved in production support Environment: Informatica - Power Center 6.1, Oracle 8i, Erwin Data Modeler, BTEQ, FastLoad, Multiload, TOAD, Windows XP, Teradata SQL Assistant Confidential Oracle Developer Responsibilities: Database design and creation. Implementing Shared Server and Archive log architecture. Implemented Java database connectivity and database connection pooling for performance enhancement. Reduced hard parsing considerably by setting proper value of CURSOR SHARING parameter. Creation of additional B-Tree Index for performance improvement. Dynamic creation of complex objects with Materialized Views and Query Rewrite for performance improvement of complex SQL statements. Developed SQL queries and stored procedures for business logic and database operations. Dynamic SQL Queries for Business Rules processing. Stored procedures for large variety of reports. Environment: Oracle 9i, SQL, PL/SQL, JBoss Web Server, JDBC, Servlets, JSPs. 